{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "faa20b26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.sql.functions import col, array, concat, lit, when, count, stddev\n",
    "from pyspark.sql.types import DoubleType, IntegerType, BooleanType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a69e0c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _id: integer (nullable = true)\n",
      " |-- _score: double (nullable = true)\n",
      " |-- sales_count_week: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- price: integer (nullable = true)\n",
      " |-- status_id: integer (nullable = true)\n",
      " |-- status_title: string (nullable = true)\n",
      " |-- stock: integer (nullable = true)\n",
      " |-- photo_MEDIUM: string (nullable = true)\n",
      " |-- photo_SMALL: string (nullable = true)\n",
      " |-- rating_average: double (nullable = true)\n",
      " |-- rating_count: integer (nullable = true)\n",
      " |-- rating_signals: integer (nullable = true)\n",
      " |-- primaryPrice: integer (nullable = true)\n",
      " |-- preparationDays: integer (nullable = true)\n",
      " |-- weight: integer (nullable = true)\n",
      " |-- categoryId: integer (nullable = true)\n",
      " |-- has_delivery: boolean (nullable = true)\n",
      " |-- has_variation: boolean (nullable = true)\n",
      " |-- new_categoryId: integer (nullable = true)\n",
      " |-- navigation_id: integer (nullable = true)\n",
      " |-- vendor_name: string (nullable = true)\n",
      " |-- vendor_identifier: string (nullable = true)\n",
      " |-- vendor_statusId: integer (nullable = true)\n",
      " |-- vendor_freeShippingToIran: integer (nullable = true)\n",
      " |-- vendor_freeShippingToSameCity: integer (nullable = true)\n",
      " |-- vendor_cityId: integer (nullable = true)\n",
      " |-- vendor_provinceId: integer (nullable = true)\n",
      " |-- vendor_has_delivery: boolean (nullable = true)\n",
      " |-- vendor_score: integer (nullable = true)\n",
      " |-- vendor_id: integer (nullable = true)\n",
      " |-- vendor_status_id: integer (nullable = true)\n",
      " |-- vendor_status_title: string (nullable = true)\n",
      " |-- vendor_owner_city: string (nullable = true)\n",
      " |-- vendor_owner_id: integer (nullable = true)\n",
      " |-- isFreeShipping: boolean (nullable = true)\n",
      " |-- IsAvailable: boolean (nullable = true)\n",
      " |-- IsSaleable: boolean (nullable = true)\n",
      " |-- mainAttribute: string (nullable = true)\n",
      " |-- categoryTitle: string (nullable = true)\n",
      " |-- published: boolean (nullable = true)\n",
      " |-- video_ORIGINAL: string (nullable = true)\n",
      " |-- promotions: string (nullable = true)"
     ]
    }
   ],
   "source": [
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"BasalamAnalysis\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Load dataset\n",
    "df = spark.read.csv('s3://bigdata-3400/BaSalam.products.csv', header=True, inferSchema=True)\n",
    "\n",
    "# Show original schema and sample data\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "83b8e107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows before cleaning: 2411358\n",
      "\n",
      "Null percentages before cleaning:\n",
      "Column '_id': 0.00% null\n",
      "Column '_score': 0.00% null\n",
      "Column 'sales_count_week': 0.00% null\n",
      "Column 'name': 0.00% null\n",
      "Column 'price': 0.00% null\n",
      "Column 'status_id': 0.00% null\n",
      "Column 'status_title': 0.11% null\n",
      "Column 'stock': 0.00% null\n",
      "Column 'photo_MEDIUM': 0.02% null\n",
      "Column 'photo_SMALL': 0.02% null\n",
      "Column 'rating_average': 0.00% null\n",
      "Column 'rating_count': 0.00% null\n",
      "Column 'rating_signals': 0.00% null\n",
      "Column 'primaryPrice': 0.00% null\n",
      "Column 'preparationDays': 0.00% null\n",
      "Column 'weight': 0.00% null\n",
      "Column 'categoryId': 6.06% null\n",
      "Column 'has_delivery': 6.06% null\n",
      "Column 'has_variation': 0.00% null\n",
      "Column 'new_categoryId': 0.00% null\n",
      "Column 'vendor_name': 0.00% null\n",
      "Column 'vendor_identifier': 0.00% null\n",
      "Column 'vendor_statusId': 0.00% null\n",
      "Column 'vendor_cityId': 0.00% null\n",
      "Column 'vendor_provinceId': 0.00% null\n",
      "Column 'vendor_has_delivery': 0.43% null\n",
      "Column 'vendor_id': 0.00% null\n",
      "Column 'vendor_status_id': 0.00% null\n",
      "Column 'vendor_status_title': 0.00% null\n",
      "Column 'vendor_owner_city': 0.00% null\n",
      "Column 'vendor_owner_id': 0.00% null\n",
      "Column 'isFreeShipping': 0.00% null\n",
      "Column 'IsAvailable': 0.00% null\n",
      "Column 'IsSaleable': 0.00% null\n",
      "Column 'categoryTitle': 0.00% null\n",
      "\n",
      "Columns remaining after threshold filtering: 35\n",
      "\n",
      "Null percentages after column filtering:\n",
      "Column '_id': 0.00% null\n",
      "Column '_score': 0.00% null\n",
      "Column 'sales_count_week': 0.00% null\n",
      "Column 'name': 0.00% null\n",
      "Column 'price': 0.00% null\n",
      "Column 'status_id': 0.00% null\n",
      "Column 'status_title': 0.11% null\n",
      "Column 'stock': 0.00% null\n",
      "Column 'photo_MEDIUM': 0.02% null\n",
      "Column 'photo_SMALL': 0.02% null\n",
      "Column 'rating_average': 0.00% null\n",
      "Column 'rating_count': 0.00% null\n",
      "Column 'rating_signals': 0.00% null\n",
      "Column 'primaryPrice': 0.00% null\n",
      "Column 'preparationDays': 0.00% null\n",
      "Column 'weight': 0.00% null\n",
      "Column 'categoryId': 6.06% null\n",
      "Column 'has_delivery': 6.06% null\n",
      "Column 'has_variation': 0.00% null\n",
      "Column 'new_categoryId': 0.00% null\n",
      "Column 'vendor_name': 0.00% null\n",
      "Column 'vendor_identifier': 0.00% null\n",
      "Column 'vendor_statusId': 0.00% null\n",
      "Column 'vendor_cityId': 0.00% null\n",
      "Column 'vendor_provinceId': 0.00% null\n",
      "Column 'vendor_has_delivery': 0.43% null\n",
      "Column 'vendor_id': 0.00% null\n",
      "Column 'vendor_status_id': 0.00% null\n",
      "Column 'vendor_status_title': 0.00% null\n",
      "Column 'vendor_owner_city': 0.00% null\n",
      "Column 'vendor_owner_id': 0.00% null\n",
      "Column 'isFreeShipping': 0.00% null\n",
      "Column 'IsAvailable': 0.00% null\n",
      "Column 'IsSaleable': 0.00% null\n",
      "Column 'categoryTitle': 0.00% null\n",
      "\n",
      "Rows remaining after removing nulls: 2262039 (93.81% of original data)\n",
      "\n",
      "Overall null percentage before cleaning: 0.36%\n",
      "Overall null percentage after cleaning: 0.00%"
     ]
    }
   ],
   "source": [
    "total_rows = df.count()\n",
    "print(f\"Total rows before cleaning: {total_rows}\")\n",
    "\n",
    "# Print null percentage for each column before cleaning\n",
    "print(\"\\nNull percentages before cleaning:\")\n",
    "for c in df.columns:\n",
    "    missing_count = df.select(\n",
    "        count(when(col(c).isNull(), c)).alias(\"missing\")\n",
    "    ).collect()[0][\"missing\"]\n",
    "    \n",
    "    missing_percent = missing_count / total_rows\n",
    "    print(f\"Column '{c}': {missing_percent:.2%} null\")\n",
    "\n",
    "# Initialize an empty list to collect final columns\n",
    "final_cols = []\n",
    "nan_threshold = 0.2\n",
    "\n",
    "# Loop over the columns and filter by null threshold\n",
    "for c in df.columns:\n",
    "    missing_count = df.select(\n",
    "        count(when(col(c).isNull(), c)).alias(\"missing\")\n",
    "    ).collect()[0][\"missing\"]\n",
    "    \n",
    "    missing_percent = missing_count / total_rows\n",
    "    \n",
    "    if missing_percent <= nan_threshold:\n",
    "        final_cols.append(c)\n",
    "\n",
    "# Select only columns that meet the threshold\n",
    "df = df.select(final_cols)\n",
    "print(f\"\\nColumns remaining after threshold filtering: {len(df.columns)}\")\n",
    "\n",
    "# Print null percentage for each column after column filtering\n",
    "print(\"\\nNull percentages after column filtering:\")\n",
    "for c in df.columns:\n",
    "    missing_count = df.select(\n",
    "        count(when(col(c).isNull(), c)).alias(\"missing\")\n",
    "    ).collect()[0][\"missing\"]\n",
    "    \n",
    "    missing_percent = missing_count / total_rows\n",
    "    print(f\"Column '{c}': {missing_percent:.2%} null\")\n",
    "\n",
    "# Drop rows with any null values\n",
    "df_clean = df.dropna()\n",
    "\n",
    "# Count remaining rows after removing nulls\n",
    "clean_count = df_clean.count()\n",
    "print(f\"\\nRows remaining after removing nulls: {clean_count} ({clean_count/total_rows:.2%} of original data)\")\n",
    "\n",
    "# Calculate overall null percentages\n",
    "before_nulls = df.select([count(when(col(c).isNull(), c)) for c in df.columns]).collect()[0]\n",
    "before_total_nulls = sum(before_nulls)\n",
    "before_total_cells = total_rows * len(df.columns)\n",
    "before_null_percent = before_total_nulls / before_total_cells\n",
    "\n",
    "after_nulls = df_clean.select([count(when(col(c).isNull(), c)) for c in df_clean.columns]).collect()[0]\n",
    "after_total_nulls = sum(after_nulls)\n",
    "after_total_cells = clean_count * len(df_clean.columns)\n",
    "after_null_percent = after_total_nulls / after_total_cells\n",
    "\n",
    "print(f\"\\nOverall null percentage before cleaning: {before_null_percent:.2%}\")\n",
    "print(f\"Overall null percentage after cleaning: {after_null_percent:.2%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
