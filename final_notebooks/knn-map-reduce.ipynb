{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8343753,"sourceType":"datasetVersion","datasetId":4956094}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from pyspark.sql import SparkSession\nfrom pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder\nfrom pyspark.ml import Pipeline\nfrom tabulate import tabulate\nfrom pyspark.sql.functions import when, col, isnan, isnull\nimport numpy as np\nimport pandas as pd\nfrom pyspark.sql import Row\nfrom pyspark.ml.classification import OneVsRest, LinearSVC\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator","metadata":{"cell_status":{"execute_time":{"duration":0.76611328125,"end_time":1714665342189.737}},"id":"7vPTp1WIWPlt","trusted":true,"execution":{"iopub.status.busy":"2025-04-26T15:23:57.731488Z","iopub.execute_input":"2025-04-26T15:23:57.732025Z","iopub.status.idle":"2025-04-26T15:24:02.365976Z","shell.execute_reply.started":"2025-04-26T15:23:57.732002Z","shell.execute_reply":"2025-04-26T15:24:02.364926Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"spark = SparkSession.builder \\\n    .appName(\"BasalamAnalysis\") \\\n    .getOrCreate()","metadata":{"cell_status":{"execute_time":{"duration":744.127197265625,"end_time":1714665406554}},"id":"RhfzwjH7WZXn","trusted":true,"execution":{"iopub.status.busy":"2025-04-26T15:24:04.407139Z","iopub.execute_input":"2025-04-26T15:24:04.407611Z","iopub.status.idle":"2025-04-26T15:24:14.591601Z","shell.execute_reply.started":"2025-04-26T15:24:04.407570Z","shell.execute_reply":"2025-04-26T15:24:14.590455Z"}},"outputs":[{"name":"stderr","text":"Setting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n25/04/26 15:24:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"### Reading the Data and Replacing numerical nans with median for each column\n","metadata":{}},{"cell_type":"code","source":"df = spark.read.csv(\"/kaggle/input/basalam-comments-and-products/BaSalam.products.csv\", header=True, inferSchema=True)\n\nmedians = {}\nfor col_name in ['sales_count_week', 'price', 'rating_average']:\n    # Use approxQuantile to calculate median (0.5 quantile)\n    median_val = df.approxQuantile(col_name, [0.5], 0.01)[0]\n    medians[col_name] = median_val\n\n# Handle null values in features columns by filling with calculated medians\ndf = df.fillna({\n    'sales_count_week': medians['sales_count_week'],\n    'price': medians['price'],\n    'rating_average': medians['rating_average']\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T15:26:24.994901Z","iopub.execute_input":"2025-04-26T15:26:24.995226Z","iopub.status.idle":"2025-04-26T15:27:10.869118Z","shell.execute_reply.started":"2025-04-26T15:26:24.995201Z","shell.execute_reply":"2025-04-26T15:27:10.865072Z"}},"outputs":[{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Step 1: Assemble the features into a vector\nfeature_cols = ['sales_count_week', 'price', 'rating_average']\n\ninteraction_assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\ndf = interaction_assembler.transform(df)\n\n# Step 2: Define the score ranges for each class\ndf = df.withColumn(\"label\", \n                               when(df[\"_score\"] < 150, 0)\n                               .when((df[\"_score\"] >= 150) & (df[\"_score\"] < 300), 1)\n                               .otherwise(2))\n\n# Step 3: Splitting the data into train, test and validation\n(train, validation, test) = df.randomSplit([0.6, 0.2, 0.2], seed=321)\ntraining_df = train.select(\"label\", \"features\")\nvalidation_df = validation.select(\"label\", \"features\")\ntest_df = test.select(\"label\", \"features\")\n\n# Step 4: Create RDD to be used in map reduce\ntraining_rdd = training_df.rdd\nvalidation_rdd = validation_df.rdd\ntest_rdd = test_df.rdd\n\n#Step 5: Repartition the RDD for better performance\ntraining_rdd = training_rdd.repartition(200)\n\n#Step 6: collect RDD elements into a list\nvalidation_list = validation_rdd.collect()\ntest_list = test_rdd.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T15:27:32.821314Z","iopub.execute_input":"2025-04-26T15:27:32.821669Z","iopub.status.idle":"2025-04-26T15:29:01.862980Z","shell.execute_reply.started":"2025-04-26T15:27:32.821647Z","shell.execute_reply":"2025-04-26T15:29:01.861611Z"}},"outputs":[{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"# KNN","metadata":{"id":"A0ZwyDGbXk6f"}},{"cell_type":"code","source":"def apply_k_nearest_neighbors(data_rdd, target_point, num_neighbors):\n  def compute_cosine_sim(vector_a, vector_b):\n    # Calculate dot product of vectors\n    dot_prod = np.dot(vector_a, vector_b)\n\n    # Determine vector magnitudes\n    norm_a = np.sqrt(np.sum(vector_a ** 2))\n    norm_b = np.sqrt(np.sum(vector_b ** 2))\n\n    # Prevent division by zero\n    if norm_a == 0 or norm_b == 0:\n        return 0\n    # Return cosine similarity value\n    return dot_prod / (norm_a * norm_b)\n\n  def partition_map(partition_data):\n      \"\"\"Partition mapping: Identify nearest neighbors in each partition.\"\"\"\n      neighbor_list = []\n      for record in partition_data:\n          label = record.label\n          features = record.features\n          # Transform PySpark vectors to NumPy arrays\n          vec_a = np.array(target_point.toArray())\n          vec_b = np.array(features.toArray())\n          # Compute similarity score\n          sim_score = compute_cosine_sim(vec_a, vec_b)\n          neighbor_list.append((None, {'score': sim_score, 'label': label}))\n      # Order neighbors by similarity score\n      neighbor_list.sort(key=lambda x: x[1]['score'], reverse=True)\n      # Select top k neighbors\n      top_neighbors = neighbor_list[:num_neighbors]\n\n      return [top_neighbors]\n\n  def aggregate_neighbors(neighbors_a, neighbors_b):\n      \"\"\"Aggregation: Combine and select top k neighbors.\"\"\"\n      # Combine neighbor lists\n      combined_neighbors = neighbors_a + neighbors_b\n      # Sort by similarity score in descending order\n      combined_neighbors.sort(key=lambda x: x[1]['score'], reverse=True)\n      # Return top k neighbors\n      return combined_neighbors[:num_neighbors]\n\n  def predict_label(neighbor_data):\n      # Extract labels and similarity scores\n      labels = np.array([item[1]['label'] for item in neighbor_data])\n      scores = np.array([item[1]['score'] for item in neighbor_data])\n      \n      # Calculate class weights (inverse of class frequency)\n      unique_labels, counts = np.unique(labels, return_counts=True)\n      class_weights = {label: 1.0/count for label, count in zip(unique_labels, counts)}\n      \n      # Initialize vote counters for each class\n      vote_counts = {}\n      \n      # Apply weighted voting\n      for i in range(len(labels)):\n          label = labels[i]\n          # Weight by similarity and class frequency\n          weight = scores[i] * class_weights[label]\n          \n          if label not in vote_counts:\n              vote_counts[label] = 0\n          vote_counts[label] += weight\n      \n      # Return class with highest weighted vote\n      return max(vote_counts.items(), key=lambda x: x[1])[0]\n\n  # Mapping stage: Process partitions to find neighbors\n  partitioned_neighbors = data_rdd.mapPartitions(partition_map)\n\n  # Aggregation stage: Combine results to get final neighbors\n  selected_neighbors = partitioned_neighbors.reduce(aggregate_neighbors)\n  return predict_label(selected_neighbors)","metadata":{"cell_status":{"execute_time":{"duration":7949.7890625,"end_time":1714665585727}},"id":"WwIh7JLp9Spq","trusted":true,"execution":{"iopub.status.busy":"2025-04-26T15:45:51.665327Z","iopub.execute_input":"2025-04-26T15:45:51.665759Z","iopub.status.idle":"2025-04-26T15:45:51.678811Z","shell.execute_reply.started":"2025-04-26T15:45:51.665735Z","shell.execute_reply":"2025-04-26T15:45:51.677808Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"# EVALUATION","metadata":{"id":"GKmtLNmbXUAk"}},{"cell_type":"code","source":"def compute_confusion_matrix(actual_labels, predicted_labels, class_labels):\n    class_count = len(class_labels)\n    matrix = [[0] * class_count for _ in range(class_count)]\n    label_indices = {lbl: idx for idx, lbl in enumerate(class_labels)}\n    for actual, predicted in zip(actual_labels, predicted_labels):\n        actual_idx = label_indices[actual]\n        predicted_idx = label_indices[predicted]\n        matrix[actual_idx][predicted_idx] += 1\n    return matrix\n\ndef compute_accuracy(matrix):\n    correct = sum(matrix[i][i] for i in range(len(matrix)))\n    total = sum(sum(row) for row in matrix)\n    return correct / total if total != 0 else 0\n\ndef compute_f1_score(prec, rec):\n    return 2 * (prec * rec) / (prec + rec) if (prec + rec) != 0 else 0\n\ndef compute_precision(matrix, cls_idx):\n    true_pos = matrix[cls_idx][cls_idx]\n    pred_pos = sum(matrix[i][cls_idx] for i in range(len(matrix)))\n    return true_pos / pred_pos if pred_pos != 0 else 0\n\ndef compute_recall(matrix, cls_idx):\n    true_pos = matrix[cls_idx][cls_idx]\n    actual_pos = sum(matrix[cls_idx])\n    return true_pos / actual_pos if actual_pos != 0 else 0\n\ndef compute_macro_precision(matrix):\n    class_count = len(matrix)\n    precisions = [compute_precision(matrix, i) for i in range(class_count)]\n    return sum(precisions) / class_count if class_count != 0 else 0\n\ndef compute_macro_recall(matrix):\n    class_count = len(matrix)\n    recalls = [compute_recall(matrix, i) for i in range(class_count)]\n    return sum(recalls) / class_count if class_count != 0 else 0\n\ndef compute_micro_precision(matrix):\n    class_count = len(matrix)\n    true_pos = sum(matrix[i][i] for i in range(class_count))\n    pred_pos = sum(sum(matrix[i][j] for j in range(class_count)) for i in range(class_count))\n    return true_pos / pred_pos if pred_pos != 0 else 0\n\ndef compute_micro_recall(matrix):\n    class_count = len(matrix)\n    true_pos = sum(matrix[i][i] for i in range(class_count))\n    actual_pos = sum(sum(row) for row in matrix)\n    return true_pos / actual_pos if actual_pos != 0 else 0\n\ndef print_confusion_matrix(matrix, class_labels):\n    print(\"Confusion Matrix:\")\n    table = [[''] + class_labels]\n    for i, label in enumerate(class_labels):\n        table.append([label] + matrix[i])\n    print(tabulate(table, tablefmt='grid'))\n\ndef assess_knn_performance(test_data):\n    predictions = []\n    actuals = []\n    for record in test_data:\n        actual_label = record.label\n        features = record.features\n        # KNN classification\n        knn_result = apply_k_nearest_neighbors(training_rdd, features, 3)\n        predictions.append(knn_result)\n        actuals.append(actual_label)\n    \n    class_labels = [0, 1, 2]  # Include all possible label values\n    conf_matrix = compute_confusion_matrix(actuals, predictions, class_labels)\n    print_confusion_matrix(conf_matrix, class_labels)\n\n    accuracy = compute_accuracy(conf_matrix)\n    macro_prec = compute_macro_precision(conf_matrix)\n    micro_prec = compute_micro_precision(conf_matrix)\n    macro_rec = compute_macro_recall(conf_matrix)\n    micro_rec = compute_micro_recall(conf_matrix)\n    f1_macro_score = compute_f1_score(macro_prec, macro_rec)\n    f1_micro_score = compute_f1_score(micro_prec, micro_rec)\n\n    metrics_table = [\n        ['Accuracy', accuracy],\n        ['Macro Precision', macro_prec],\n        ['Micro Precision', micro_prec],\n        ['Macro Recall', macro_rec],\n        ['Micro Recall', micro_rec],\n        ['Macro F1 Score', f1_macro_score],\n        ['Micro F1 Score', f1_micro_score]\n    ]\n    print(tabulate(metrics_table, tablefmt='grid'))","metadata":{"cell_status":{"execute_time":{"duration":0.60498046875,"end_time":1714665586709.087}},"id":"bw9VS-N5LBMF","trusted":true,"execution":{"iopub.status.busy":"2025-04-26T15:51:59.257948Z","iopub.execute_input":"2025-04-26T15:51:59.258319Z","iopub.status.idle":"2025-04-26T15:51:59.276069Z","shell.execute_reply.started":"2025-04-26T15:51:59.258294Z","shell.execute_reply":"2025-04-26T15:51:59.275141Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"assess_knn_performance(validation_list[:500])","metadata":{"cell_status":{"execute_time":{"duration":0.404052734375,"end_time":1714666460440.801}},"colab":{"base_uri":"https://localhost:8080/"},"id":"IJiSuP26V7tO","outputId":"b9fb60fd-8397-44b8-cd50-9da915441407","trusted":true,"execution":{"iopub.status.busy":"2025-04-26T17:48:16.679928Z","iopub.execute_input":"2025-04-26T17:48:16.682193Z","iopub.status.idle":"2025-04-26T22:06:33.326846Z","shell.execute_reply.started":"2025-04-26T17:48:16.682132Z","shell.execute_reply":"2025-04-26T22:06:33.325432Z"}},"outputs":[{"name":"stderr","text":"[Stage 1449:======================================================================> (197 + 3) / 200]\r","output_type":"stream"},{"name":"stdout","text":"Confusion Matrix:\n+---+----+-----+----+\n|   |  0 |   1 |  2 |\n+---+----+-----+----+\n| 0 | 28 |   2 |  0 |\n+---+----+-----+----+\n| 1 | 81 | 353 |  0 |\n+---+----+-----+----+\n| 2 |  0 |   0 | 36 |\n+---+----+-----+----+\n+-----------------+----------+\n| Accuracy        | 0.834    |\n+-----------------+----------+\n| Macro Precision | 0.750416 |\n+-----------------+----------+\n| Micro Precision | 0.834    |\n+-----------------+----------+\n| Macro Recall    | 0.915566 |\n+-----------------+----------+\n| Micro Recall    | 0.834    |\n+-----------------+----------+\n| Macro F1 Score  | 0.824805 |\n+-----------------+----------+\n| Micro F1 Score  | 0.834    |\n+-----------------+----------+\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"}],"execution_count":20}]}